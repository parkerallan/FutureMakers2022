{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day_9_Introduction_to_Loss_Functions_PA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parkerallan/FutureMakers2022/blob/main/Day%209/Day_9_Introduction_to_Loss_Functions_PA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "861ncVuLPeyF"
      },
      "source": [
        "![image_2021-10-30_133041.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Day 9 Objectives: \n",
        "* To introduce you to loss functions. \n"
      ],
      "metadata": {
        "id": "5rokz_Xr0kDG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCtJpzBrYWqr"
      },
      "source": [
        "# Loss Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4fAWIkUYUyR"
      },
      "source": [
        "Loss functions define what a good prediction is and isn’t. Choosing the right loss function dictates how well your estimator (machine learning model) will be. The criteria by which an estimator is scrutinized is its performance - how accurate the model's decisions are. This calls for a way to measure how far a particular iteration of the model is from the actual values. This is where loss functions come into play.\n",
        "\n",
        "Loss functions measure how far an estimated value is from its true value. A loss function maps decisions to their associated costs. Loss functions are not fixed, they change depending on the task in hand and the goal to be met.\n",
        "\n",
        "Worth to note we can speak of different kind of loss functions: **regression loss** functions and **classification loss** functions.\n",
        "\n",
        "Regression loss function describes the difference between the values that a model is predicting and the actual values of the labels. So the loss function has a meaning on a labeled data when we compare the prediction to the label at a single point of time. This loss function is often called the error function or the error formula. Typical error functions we use for regression models are L1 and L2, Huber loss, Quantile loss, log cosh loss.\n",
        "\n",
        "**Note**: L1 loss is also know as Mean Absolute Error. L2 Loss is also know as Mean Square Error or Quadratic loss.\n",
        "\n",
        "Loss functions for classification represent the price paid for inaccuracy of predictions in classification problems (problems of identifying which category a particular observation belongs to). To name a few: log loss, focal loss, exponential loss, hinge loss, relative entropy loss and other.\n",
        "\n",
        "*Note*: While more commonly used in regression, the square loss function can be re-written and utilized for classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I1Y9BQxq72l"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6Hpicvr6XJ0"
      },
      "source": [
        "# Regression Losses\n",
        "\n",
        "Remember, in regression, the output would be a real value. We need some loss functions which compares two real values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMoFFw2VUR7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93d1b8ee-ec9f-485a-8fea-d09fe7b8e627"
      },
      "source": [
        "(train_features, train_labels), (test_features, test_labels) = keras.datasets.boston_housing.load_data()\n",
        "\n",
        "# get per-feature statistics (mean, standard deviation) from the training set to normalize by\n",
        "train_mean = np.mean(train_features, axis=0)\n",
        "train_std = np.std(train_features, axis=0)\n",
        "train_features = (train_features - train_mean) / train_std"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n",
            "65536/57026 [==================================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAdSFpdB6aDH"
      },
      "source": [
        "## Mean Squared Error [MSE]\n",
        "\n",
        "As the name suggests, Mean square error is measured as the average of squared difference between predictions and actual observations. It’s only concerned with the average magnitude of error irrespective of their direction. \n",
        "\n",
        "However, due to squaring, predictions which are far away from actual values are penalized heavily in comparison to less deviated predictions. Plus MSE has nice mathematical properties which makes it easier to calculate gradients.\n",
        "\n",
        "Let's assume there are $n$ data samples, for $i^{th}$ sample; the actual output is $y_i$ and $\\hat{y}_i$ is the estimated output from the regression model. \n",
        "\n",
        "We first square the difference between the original and estimated output with $(y_i - \\hat{y}_i)^2$. Then we take sum of the squared difference for all the samples. And finally divide it by the total count of samples, which is $n$. \n",
        "\n",
        "$$MSE = \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{n}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5OO5ZfoYtCJ"
      },
      "source": [
        "model = keras.Sequential([\n",
        "        tf.keras.layers.Dense(10, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(50, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(20, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='mse',\n",
        "              metrics=['mse'])\n",
        "\n",
        "mse_model = model.fit(train_features, train_labels, epochs=250, validation_split = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEFaa0VQaKef"
      },
      "source": [
        "## Question 1\n",
        "\n",
        "Now that you know how MSE works, you need to plot the behavior of MSE for the synthetic errors given.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc5OFsCmadXE"
      },
      "source": [
        "### Answer 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mse_model.history.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5ier89AqXny",
        "outputId": "a2db9666-7c9d-43fc-bb46-c6cdb1d43d9e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'mse', 'val_loss', 'val_mse'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8RF_LUDbdo2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "54e3f360-bad3-459b-c7e3-c639717c7808"
      },
      "source": [
        "errors = np.arange(0, 250)\n",
        "\n",
        "plt.plot(errors, mse_model.history['mse'], c='#ED4F46', marker='o')\n",
        "plt.grid()\n",
        "plt.xlabel('Difference between actual and estimated ouputs')\n",
        "plt.ylabel('Mean Squared Errors')\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xcdZ3/8dc7vaRpegmlpfIDtKisCLoiZBW8tdQb4gX8eV0pYhfpsqCCrhdcXRd396fgrguigla5FMpa70u3ywrYkioqSCu1UApSEaQVaUvpLS2hbT6/P8530mk6k0zSTCaZ834+HvPIOd9z5sznO5PMJ9/zPef7VURgZmYG0FDrAMzMbOhwUjAzsy5OCmZm1sVJwczMujgpmJlZl5G1DuBATJ48OaZNm9av57a3t9Pc3DywAQ1xeawz5LPernM+9LfOy5cv3xgRU0ptG9ZJYdq0aSxbtqxfz21ra2PGjBkDG9AQl8c6Qz7r7TrnQ3/rLOnRctt8+sjMzLo4KZiZWRcnBTMz61LVpCCpRdIPJD0gabWkkyRNknSbpIfSz4PSvpJ0haQ1klZKOr6asZmZ2f6q3VL4CvCTiDgaeAmwGrgIWBwRRwGL0zrAm4Cj0mMOcFWVYzMzs26qlhQkTQReA1wNEBHPRMRm4DRgXtptHnB6Wj4NuD4ydwItkg4d6Lg6li5h8zln8uLLv8jmc86kY+mSgX4JM7NhS9UaJVXSccBc4H6yVsJy4AJgXUS0pH0EPBURLZIWAZdExB1p22LgUxGxrNtx55C1JJg6deoJCxYsqDimlgdWcfhPb6Zh9+6uss6RI1n7ulPZfPSx/a/sMLF9+3bGjRtX6zAGXR7r7TrnQ3/rfPLJJy+PiNZS26p5n8JI4HjgwxFxl6SvsPdUEQAREZL6lJUiYi5ZsqG1tTX6co3u5huvprMoIQA07N7NtOV30nLu+X0JY1jK43XckM96u875UI06V7NPYS2wNiLuSus/IEsSTxROC6Wf69P2dcARRc8/PJUNmM6NG/pUbmaWN1VLChHxZ+AxSS9IRa8lO5W0EDgrlZ0F3JSWFwLvT1chnQhsiYjHBzKmhskl7+ouW25mljfVHubiw8CNkkYDDwOzyRLR9ySdDTwKvDvtezNwKrAG2JH2HVBNs2bTfuXl0NGxt7CxkaZZA/5SZmbDUlWTQkSsAEp1Zry2xL4BVPXEfuP0mQDsnH8tezasRwAdHeycf+0+283M8ip3dzQ3Tp+ZtQykrrLODetpv/JyX55qZrmXu6QAWUtB3S/FLWoxmJnlVS6Tgq9CMjMrLZdJwVchmZmVlsuk0DRrNp0ju/Wx+yokM7N8JoXG6TNZ+7pTobERgIYph9B83oW++sjMci+XSQFg89HHMur47GrZzo0b2Dn/Wl99ZGa5l9uk0PLAKnbd/etsJcKXpZqZkeOk8KxftMHuXfsW+rJUM8u53CaFUdu2liz3Zalmlme5TQq7xk8oWe7LUs0sz3KbFP78yhldVx918WWpZpZzuU0Km48+lubzLoTGMYAvSzUzg+oPnT2kNU6fyZ4/reXp7/0nE6+8Bo0aVeuQzMxqKrcthYIRU6Zml6Q+ubHWoZiZ1Vzuk0LDlEMA6NzwRI0jMTOrvdwnhd2P/B6Abf/4KTafc6ZvXjOzXMt1UuhYuoSdN17fte67ms0s73KdFHbOvxae6di30Hc1m1mO5TopeLIdM7N95TopeLIdM7N95TopNM2a7buazcyK5P7mNYD2b3wVdu6gYcohNM2a7buazSy3cp0UIEsMsWUzO675JhMuu5KGceNrHZKZWc1U9fSRpEck3StphaRlqWySpNskPZR+HpTKJekKSWskrZR0fDVj2yfOiS0AxJbNg/WSZmZD0mD0KZwcEcdFRGtavwhYHBFHAYvTOsCbgKPSYw5w1SDEBkDDxIkAdG7ZMlgvaWY2JNWio/k0YF5angecXlR+fWTuBFokHToYAWmCWwpmZlD9pBDArZKWS5qTyqZGxONp+c/A1LR8GPBY0XPXprKqa2jJkkKnk4KZ5Vy1O5pfFRHrJB0C3CbpgeKNERGSoi8HTMllDsDUqVNpa2vrV2Dbt2/veq727OHFwMMrVrB+zLh+HW84KK5znuSx3q5zPlSjzlVNChGxLv1cL+nHwMuAJyQdGhGPp9ND69Pu64Ajip5+eCrrfsy5wFyA1tbWmDFjRr9ia2tro/i5T11zJc+ZdBDH9PN4w0H3OudFHuvtOudDNepctdNHkpoljS8sA28A7gMWAmel3c4CbkrLC4H3p6uQTgS2FJ1mqjpNbHGfgpnlXjVbClOBH0sqvM5/RsRPJN0NfE/S2cCjwLvT/jcDpwJrgB3AoN1W3LF0CZ3rn+CZP61l8+8e8A1sZpZbVUsKEfEw8JIS5U8Cry1RHsD51YqnnI6lS2i/8nLYvQvYO3w24MRgZrmT67GPIA2f3eHhs83MwEnBw2ebmRXJfVLw8NlmZnvlPil4+Gwzs708SmrqTN5x9VXE1q3ooEmM/cA57mQ2s1zKfUsBssQw7qPZuHzjPvlZJwQzyy0nhUTNzQBE+/YaR2JmVjtOComaszGPor29xpGYmdWOk0KyNym4pWBm+eWkkKh5LOCkYGb55qSQaNRoGN3o00dmlmtOCkXU3OyWgpnlWq9JQdKXJE2QNErSYkkbJM0ajOAGm5rHuaVgZrlWSUvhDRGxFXgL8AjwfOAT1QyqVhqam+l0UjCzHKskKYxKP98MfD8itlQxnppS8zhih08fmVl+VZIUFqa5lU8AFkuaAjxd3bBqI+tTcEvBzPKrx6QgqQH4b+AVQGtE7CKbFe20QYht0GV9Cm4pmFl+9ZgUIqIT+HpEbIqIPamsPSL+PCjRDaKOpUvoWLqE2LKFzeecScfSJbUOycxs0FVy+mixpHcoTbZcj7qm5Ny5A9g7JacTg5nlTSVJ4W+B7wPPSNoqaZukrVWOa1B5Sk4zs0yv8ylExPjBCKSWPCWnmVmmokl2JL0NeE1abYuIRdULafA1TJ5C54b1JcvNzPKkkjuaLwEuAO5PjwskfbHagQ0mT8lpZpappKVwKnBcuhIJSfOAe4BPVzOwwdQ1Jed1c4mnnkITJjL27HM9A5uZ5U6lA+K1FC1PrEYgtdY4fSYTvvBlAMbOnuOEYGa5VElS+AJwj6TrUithOfD/Kn0BSSMk3SNpUVo/UtJdktZI+q6k0am8Ma2vSdun9b06B0ZNaU6FnTsH+6XNzIaESu5o7gROBH4E/BA4KSK+24fXuABYXbR+KXBZRDwfeAo4O5WfDTyVyi9L+w0qNTUBEE87KZhZPlVyR/MnI+LxiFiYHhXfzSzpcLKB9L6d1gXMBH6QdpkHnJ6WT0vrpO2vHfQb5kY3QkODWwpmlluVdDT/VNLHge8CXaPFRcSmCp57OfBJoHCvw8HA5ojYndbXAoel5cOAx9Kxd0vakvbfWHxASXOAOQBTp06lra2tgjD2t3379pLPPXbkKB576Hc83s/jDmXl6lzv8lhv1zkfqlHnSpLCe9LP84vKAnhuT0+S9BZgfUQslzSjf+HtLyLmAnMBWltbY8aM/h26ra2NUs996oZvcfjkybygn8cdysrVud7lsd6ucz5Uo849JoXUp3BRH/sQCl4JvE3SqcAYYALwFaBF0sjUWjgcWJf2XwccAayVNJLsKqcn+/G6B0RjxhBpDCQzs7yppE+hX7OsRcSnI+LwiJgGvBdYEhFnALcD70y7nQXclJYXpnXS9iUREf157QOhprHuUzCz3KrkktSfSvq4pCMkTSo8DuA1PwV8TNIasj6Dq1P51cDBqfxjwEUH8Br9pqYmtxTMLLeq1qdQLCLagLa0/DDwshL7PA28q9JjVouamujc4IHwzCyfKhkl9cjBCGSo0Bi3FMwsv8qePpL0yaLld3Xb9oVqBlVL2ekj9ymYWT711Kfw3qLl7oPfnVKFWIYENY31Hc1mlls9JQWVWS61XjfU1AQdHcSePbUOxcxs0PWUFKLMcqn1+jGmMP7R0zUOxMxs8PXU0fySNBezgKaieZlFdjNaXSoMisfOHdDcXNtgzMwGWdmkEBEjBjOQoaJr+Gz3K5hZDlU6yU5uaEzWCPIVSGaWR04K3ex68AEAtn7iI2w+50w6li6pcURmZoPHSaFIx9IldNz0g671zg3rab/ycicGM8sNJ4UiO+dfC7t27VvY0ZGVm5nlQNmOZknb6OHS04iYUJWIaqhzY+kxj8qVm5nVm56uPhoPIOlfgMeBG8guRz0DOHRQohtkDZOn0LlhfclyM7M8qOT00dsi4sqI2BYRWyPiKrL5lOtO06zZ0Ni4b2FjY1ZuZpYDlSSFdklnSBohqUHSGRTN1VxPGqfPpPm8C7vWG6YcQvN5F9I4fWYNozIzGzyVJIX3Ae8GnkiPd6WyutQ4fSaaOJHGU95Cy7ducEIws1ypZD6FR6jT00XlqHGM72g2s1zqtaUg6S8kLZZ0X1r/S0mfrX5otaMxTR4Qz8xyqZLTR98im09hF0BErGTfuRbqT5OTgpnlUyVJYWxE/Lpb2e5qBDNUaMwY8OkjM8uhSpLCRknPI93IJumdZPct1K2sT8EtBTPLn147moHzgbnA0ZLWAX8gu4GtbqmpyR3NZpZLPSYFSSOA8yLidZKagYaI2DY4odWOxrilYGb51GNSiIg9kl6VluvyhrVSfEmqmeVVJaeP7pG0EPg+RXcyR8SPqhZVrTU1QUcH0dmJGjyQrJnlRyXfeGOAJ4GZwFvT4y29PUnSGEm/lvRbSaskfT6VHynpLklrJH1X0uhU3pjW16Tt0/pbqQOlMU0QAc88U6sQzMxqopI7mvs7GlwHMDMitksaBdwh6X+BjwGXRcQCSd8AzgauSj+fiojnS3ovcCnwnn6+9gFRY5qS8+mdXdNzmpnlQa9JQdIYsi/sY8laDQBExN/09LyICGB7Wh2VHkHW4iiMnTQPuJgsKZyWlgF+AHxNktJxBpWaCknBnc1mli+V9CncADwAvBH4Z7LLUVdXcvB09dJy4PnA14HfA5sjonDz21rgsLR8GPAYQETslrQFOBjY2O2Yc4A5AFOnTqWtra2SUPazffv2ss+d8PuHmQbc/fOf8/SUQ/p1/KGopzrXszzW23XOh6rUOSJ6fAD3pJ8r089RwJ29Pa/bMVqA24FXAWuKyo8A7kvL9wGHF237PTC5p+OecMIJ0V+333572W3P/GZZPHnaG+KZ1ff1+/hDUU91rmd5rLfrnA/9rTOwLMp8r1bS0VyYtHizpBcBE4E+/fscEZtTUjgJaJFUaKEcDqxLy+tSkiBtn0jWwT34Cv0IPn1kZjlTSVKYK+kg4B+BhcD9wJd6e5KkKZJa0nIT8Hqy0063A+9Mu50F3JSWF6Z10vYlKaMNukLnsvsUzCxvKrn66NtpcSnw3D4c+1BgXupXaAC+FxGLJN0PLJD0r8A9wNVp/6uBGyStATZRw5FYNaYJgNjpG9jMLF8qufroc6XKI+Kfe3peZENsv7RE+cPAy0qUP002q1vNdbUUOtxSMLN8qeTqo+LhLcaQ3bhW0dVHw1VXS8FDXZhZzlRy+ujLxeuS/h24pWoRDQEdd/0CgJ3XfZuO/1lI06zZnqvZzHKhPwP7jCW7aqgudSxdwo6rruha79ywnvYrL6dj6ZIaRmVmNjgq6VO4lzTBDjACmEJ2E1td2jn/Wujo2Lewo4Od8691a8HM6l4lfQrFg9/tBp6IvXck153OjRv6VG5mVk8qSQrdJ9WZIKlrJSI2DWhENdYweQqdG9aXLDczq3eV9Cn8BtgA/A54KC0vT49l1QutNppmzYbGxn0LGxuzcjOzOldJUrgNeGtETI6Ig8lOJ90aEUdGRF9uZhsWGqfPpPm8C2HUKAAaphxC83kXuj/BzHKhktNHJ0bEOYWViPhfSb0OczGcNU6fyTO/uoPOx//ExK98o9bhmJkNmkqSwp8kfRaYn9bPAP5UvZCGhmyeZt/RbGb5Usnpo78muwz1x+lxSCqra2oa4zuazSx3KrmjeRNwAUAaLXVzrUYvHUwa0+SkYGa5U7alIOlzko5Oy42SlgBrgCckvW6wAqyZxjHQ0UF0dtY6EjOzQdPT6aP3AA+m5bPSvocA04EvVDmumivM07zf3c1mZnWsp6TwTNFpojcC34mIPRGxmso6qIc1j5RqZnnUU1LokPQiSVOAk4Fbi7aNrW5YtafGwuxrTgpmlh89/cd/AfADsiuPLouIPwBIOpVsxrS6pqZCS8GXpZpZfpRNChFxF3B0ifKbgZurGdRQ4HmazSyP+jOfQj64T8HMcshJoYxCSwG3FMwsR5wUyvDVR2aWRxVdWirpFcC04v0j4voqxTQkdCWFnW4pmFl+VDId5w3A84AVwJ5UHECdJwVfkmpm+VNJS6EVOCYP4x3tY/RokIgOtxTMLD8q6VO4D3hWXw8s6QhJt0u6X9IqSYVB9SZJuk3SQ+nnQalckq6QtEbSSknH9/U1B5IaGrLxj3a6pWBm+VFJUpgM3C/pFkkLC48Knrcb+PuIOAY4EThf0jHARcDiiDgKWJzWAd4EHJUec4Cr+liXAacxnlPBzPKlktNHF/fnwBHxOPB4Wt4maTVwGHAaMCPtNg9oAz6Vyq9Pp6nulNQi6dB0nJrQmDE+fWRmuaLB6CqQNA34GfAi4I8R0ZLKBTwVES2SFgGXRMQdadti4FMRsazbseaQtSSYOnXqCQsWLOhXTNu3b2fcuHFlt7c8sIrDb12EOjvZNX4Cf37lDDYffWy/Xmuo6K3O9SqP9Xad86G/dT755JOXR0RrqW2VXH10IvBV4IXAaGAE0B4REyp5cUnjgB8CF0bE1iwPZCIiJPUpK0XEXGAuQGtra8yYMaMvT+/S1tZGued2LF1C++23QJpLYfS2rTz79lt44QtfSOP0mf16vaGgpzrXszzW23XOh2rUuZI+ha+RTb/5ENAEfBD4eiUHlzSKLCHcGBE/SsVPSDo0bT8UWJ/K1wFHFD398FQ26HbOv3b/eRQ6OrJyM7M6VtEdzRGxBhiR5lO4Fjilt+ekU0NXA6sj4j+KNi0km7SH9POmovL3p6uQTgS21Ko/oXPjhj6Vm5nVi0o6mndIGg2skPQlss7jSpLJK4EzgXslrUhl/wBcAnxP0tnAo8C707abgVPJpvzcAcyuuBYDrGHyFDo3rC9ZbmZWzypJCmeSJYEPAR8lO8Xzjt6elDqMVWbza0vsH8D5FcRTdU2zZtN+5eX7nkJqbKRpVs3ylJnZoOg1KUTEo5KagEMj4vODEFPNFTqT27/5NdjRTsPkQ2g6c/aw7mQ2M6tEr6eBJL2VbNyjn6T14yq8eW1Ya5w+k7HvnQXAhMuvckIws1yopG/gYuBlwGaAiFgBHFnFmIYMjW0GIHa01zgSM7PBUUlS2BURW7qV5WJwPI0dCzgpmFl+VNLRvErS+4ARko4CPgL8srphDQ1qTi2FdicFM8uHSloKHwaOBTqA7wBbgQurGdRQ4dNHZpY3lVx9tAP4THrkyt6ksKPGkZiZDY6ySaG3K4wi4m0DH87Q4tNHZpY3PbUUTgIeIztldBflb0SrWz59ZGZ501NSeBbwerLB8N4H/A/wnYhYNRiBDQUaPRpGjnJSMLPcKNvRnAa/+0lEnEU2c9oaoE3ShwYtuiFAzWOdFMwsN3rsaJbUCLyZrLUwDbgC+HH1wxo6NLbZfQpmlhs9dTRfTzZT2s3A5yPivkGLagjR2GZffWRmudFTS2EW0A5cAHykaMY0kQ1qWtHMa8NdlhTcUjCzfCibFCKiogl46p2am+n8U00mgDMzG3T+4u9Bx9Il7LpnOXv++AibzzmTjqVLah2SmVlVVTL2US51LF2yz0Q7nRvWZ+vgYbTNrG65pVDGzvnX7jvzGkBHR1ZuZlannBTK6Ny4oU/lZmb1wEmhjIbJU/pUbmZWD5wUymiaNRsaG/ctbGzMys3M6pQ7mssodCbvmPdtYtOTaPx4xn7wPHcym1ldc0uhB43TZ9LyjesAGPPW/+uEYGZ1z0mhFxo9Go2fQOemJ2sdiplZ1TkpVKBh0sFOCmaWC1VLCpKukbRe0n1FZZMk3SbpofTzoFQuSVdIWiNppaTjqxVXfzRMmuSkYGa5UM2WwnXAKd3KLgIWR8RRwOK0DvAm4Kj0mANcVcW4+kyTJjspmFkuVC0pRMTPgE3dik8D5qXlecDpReXXR+ZOoEXSodWKra86t20lNj3Jpref4jGQzKyuKSKqd3BpGrAoIl6U1jdHREtaFvBURLRIWgRcEhF3pG2LgU9FxLISx5xD1ppg6tSpJyxYsKBfsW3fvp1x48b1ul/LA6s4/NZFNHR2dpV1jhzJ2tedyuajj+3Xa9dKpXWuN3mst+ucD/2t88knn7w8IlpLbavZfQoREZL6nJEiYi4wF6C1tTVmzJjRr9dva2ujkuduvvFqOosSAkDD7t1MW34nLeee36/XrpVK61xv8lhv1zkfqlHnwb766InCaaH0c30qXwccUbTf4ams5jwGkpnlyWAnhYXAWWn5LOCmovL3p6uQTgS2RMTjgxxbSR4DyczypJqXpH4H+BXwAklrJZ0NXAK8XtJDwOvSOmTzQD8MrAG+BZxXrbj6ymMgmVmeVK1PISL+usym15bYN4AheYK+MLRF+9f+A3btAkCjG3t6ipnZsOU7mitV1CUe27bSfuXlvjTVzOqOk0IFds6/Fnbv2rfQs7CZWR1yUqhA2SuQNqwvWW5mNlw5KVSgpyuNfArJzOqJk0IFerrSyKeQzKyeOClUoKfJdXwTm5nVEyeFCjVMOaT0hpyNtWJm9c1JoUJNs2bDiBH7b9i50/0KZlY3nBQq1Dh9JhrbvP+G3btp//aVgx+QmVkVOCn0QWzfVnrDtm1uLZhZXXBS6IOeLk1t/8q/OTGY2bDnpNAHPQ6C19npoS/MbNhzUuiDxukz0fgJ5Xfo6HD/gpkNa04KfTT2g3+3/1DaxbZtY9N7T3eLwcyGJSeFPmqcPpPm8y6Ehh7euqd30n7ZpTx15rucHMxsWHFS6IfG6TNpvuATve4X27bSftmlbjmY2bDhpNBPvfYvFEstBycHMxvqnBQOwNgP/l3fnlBIDqe/kU2nv9Gnl8xsyKnadJx50Dh9JrtWr+KZnyzq1/MLp5faL7t0v20aP4GxH/y7HgfjMzMbaE4KB2jcuR+m44XHZpeibitzx3M/9JQwijl5mNlAclIYAI3TZ3Z9KW//xlf73XLoj0qTB8CLgU2Xf7HX/ZxozPLLSWGAdbUcrrwcOjpqHc4+VOF+fUk0teYEZjawnBSqoNBy6Fi6ZMBPK9m+KklglbaQ6smwqrMEETB+PELEtq3ZfUCdnTRMOYSmWbOd9AeRIqLWMfRba2trLFu2rF/PbWtrY8aMGQMbUA+cIMyqK6i8NTzspUT6zPgJHNSPlrKk5RHRWmrbkGopSDoF+AowAvh2RFxS45AGTHG/Q8fSJeycfy2dG9bXOCqz+pGbhABZywoYvW1rdqqanqcN7oshkxQkjQC+DrweWAvcLWlhRNxf28gGXnGCKMWtCjOrWEcHO+dfW39JAXgZsCYiHgaQtAA4Dai7pNCb3pIG9K+1kavmtVmOdG7cMGDHGkpJ4TDgsaL1tcDLaxTLkFdJ4uiut34Ut1DMhqeeJgDrq6GUFCoiaQ4wB2Dq1Km0tbX16zjbt2/v93OHq97r3ABnf2iwwjkgLQ+s4v/cfisjOp6udSg2ALq3YN2qrVznyJH88YQT2TxA32dD5uojSScBF0fEG9P6pwEioux1dcPp6qOhII91hnzWezjVuXsLVeMnMOqVr+GZXyztU6s1V4kkJ1cf3Q0cJelIYB3wXuB9tQ3JzKqt7KnQcz/cp+MMp0Q4UNra2pgxfcaAHnPIJIWI2C3pQ8AtZJekXhMRq2oclplZrgyZpAAQETcDN9c6DjOzvPJ8CmZm1sVJwczMujgpmJlZlyFzSWp/SNoAPNrPp08GNg5gOMNBHusM+ay365wP/a3zcyKi5B1vwzopHAhJy8pdp1uv8lhnyGe9Xed8qEadffrIzMy6OCmYmVmXPCeFubUOoAbyWGfIZ71d53wY8Drntk/BzMz2l+eWgpmZdeOkYGZmXXKZFCSdIulBSWskXVTreKpF0iOS7pW0QtKyVDZJ0m2SHko/D6p1nAdC0jWS1ku6r6isZB2VuSJ97islHV+7yPuvTJ0vlrQufdYrJJ1atO3Tqc4PSnpjbaI+MJKOkHS7pPslrZJ0QSqv28+6hzpX97OOiFw9yEZg/T3wXGA08FvgmFrHVaW6PgJM7lb2JeCitHwRcGmt4zzAOr4GOB64r7c6AqcC/0s27P6JwF21jn8A63wx8PES+x6TfscbgSPT7/6IWtehH3U+FDg+LY8HfpfqVrefdQ91rupnnceWQtdc0BHxDFCYCzovTgPmpeV5wOk1jOWARcTPgE3disvV8TTg+sjcCbRIOnRwIh04ZepczmnAgojoiIg/AGvI/gaGlYh4PCJ+k5a3AavJpvCt28+6hzqXMyCfdR6TQqm5oHt6o4ezAG6VtDxNYwowNSIeT8t/BqbWJrSqKlfHev/sP5ROlVxTdFqw7uosaRrwUuAucvJZd6szVPGzzmNSyJNXRcTxwJuA8yW9pnhjZG3Our4mOQ91TK4CngccBzwOfLm24VSHpHHAD4ELI2Jr8bZ6/axL1Lmqn3Uek8I64Iii9cNTWd2JiHXp53rgx2RNyScKzej0c33tIqyacnWs288+Ip6IiD0R0Ql8i72nDeqmzpJGkX053hgRP0rFdf1Zl6pztT/rPCaFrrmgJY0mmwt6YY1jGnCSmiWNLywDbwDuI6vrWWm3s4CbahNhVZWr40Lg/enKlBOBLUWnHoa1bufL3072WUNW5/dKakzznx8F/Hqw4ztQkgRcDayOiP8o2lS3n3W5Olf9s651D3uNevVPJevJ/z3wmVrHU6U6PpfsSoTfAqsK9QQOBhYDDwE/BSbVOtYDrOd3yJrQu8jOoZ5dro5kV6J8PX3u9wKttY5/AOt8Q6rTyvTlcGjR/p9JdX4QeFOt4+9nnV9FdmpoJbAiPU6t58+6hzpX9Ullej0AAAglSURBVLP2MBdmZtYlj6ePzMysDCcFMzPr4qRgZmZdnBTMzKyLk4KZmXVxUqgBSXvS6IarJP1W0t9LakjbWiVdkZYbJf007fseSa9Oz1khqam2tShN0vY+7n+6pGOqFU81SJom6X0HeIw2SQM+yfxAHFfSDEmvKFo/V9L7Dzw6kPQP/XjOByR9bSBevx+vvc97kQdOCrWxMyKOi4hjgdeTDUPxTwARsSwiPpL2e2kqOy4ivgucAXwxre/s7UXSjTtD/TM+nWx0x+FkGnBASWGImwF0fRFGxDci4voBOnafk0KNzaDovciFWt+gkccHsL3b+nOBJ8luuJkBLAIOIRvlcAvZTSt/SzYy5h/IbnkH+ATZHdorgc+nsmlkN65cT3bT2nN62G812W3yq4Bbgaa07flkNwL9FvgN8Lxyr1eqbsBl6ZiLgSmp/HnAT4DlwM+Bo8n+2Ap1WgG8HFie9n8J2Y07z07rvwfGAlPIbvu/Oz1embY3A9eQ3cF5D3BaKv8A8KP02g8BXyoT9+fS8e4jm/dW5d4L4M6iz+Wj6TW+VnSsRcCMtHwVsCy9H58v2qeNEjdU9RBHG3Bpqt/vgFen8iaykX5Xkw1lcleZ454ALE3v/y2kG56AjwD3p890Qfq9+DPZ8AgrgFdTNFRziuOyVKfVwF+l9/ch4F+LXu+/0mutAuakskuAPem4hd/hWalOK4BvkoZ6Bmanev6a7Hf0ayXqNCm9zsr0mfxlKu+KN63fl+o1DXgAuDHF/gNgbNrnEdIw80Brqmep9+Jd6Xi/BX5W6++Sqnw/1TqAPD7olhRS2WayER5nAItSWddyWr8OeGdafkPhS4OsxbeIbJz9aUAncGIF++0Gjkv7fQ+YlZbvAt6elseQfRmXPE6JegRwRlr+XOGPmSxBHJWWXw4s6V6ntL4KmAB8iOzL8QyyxPartP0/yQb6A3g22RAAAF8oir+F7AulmewL+2FgYqrLo8ARJeKeVLR8A/DWHt6L7p/LByifFAp32I4g+6IpfHG1UfrLu1wcbcCX0/KpwE/T8seAa9LyX6bPtLXbMUcBv2Rvgn5P0XP+BDQW3rf082L2/VLtWk9xFOYsuCA9/1CyMfzXAgd3q3cT2ZdooXx70XFfCPw3MCqtXwm8Px3vj2T/AIwGfkHppPBV4J/S8kxgRZn4i5NCsPcfiWuK6vUI3ZJCmWPdCxxW/H7V22MkNly9IT3uSevjyMY6+SPwaGRjyPe23x8iYkUqXw5MS+MlHRYRPwaIiKcBJJU7zs+6xdUJfDctzwd+lEZ5fAXw/Ww4FyD7Einll8AryRLXF4BTyBLRz9P21wHHFB1nQjr+G4C3Sfp4Kh9DljQAFkfEllSP+8mSTPEQwwAnS/ok2Zf+JGCVpLYy70WZ0Et6dxq2fCTZl90xZP/ZlrNfHGRfnJD9Rw7ps0rLrwGuSPGtlFTq2C8AXgTclmIfQTZMBimWGyX9F9l/3ZUojBV2L7Aq0phCkh4mG5DtSeAjkt6e9juC7HflyW7HeS1ZC+buFFcT2YB2Lyf7Ut6Qjvtd4C9KxPEq4B2p7kskHSxpQi+xPxYRv0jL88laSv/ea433+gVwnaTvsffzqCtOCkOApOeSNavXk/33VNHTyPoXvtntWNOA9gr36ygq2kP2R9mn16tAkLUsNkfEcRXs/zOyZvpzyAY3+1Q6xv+k7Q1kraCn9wku+1Z5R0Q82K385exfz5Hd9hlD9l9qa0Q8JulisqRSqd3s2z83Jh33SODjwF9FxFOSruvpuBXEUajHfnXohci+vE8qse3NZInlrcBnJL24guMV4uhk3/e2ExgpaQZZ8j4pInak5Fqq3gLmRcSn9ymUDnTip5KfR9J9XJ/CevFzyn5GEXFu+p16M7Bc0gkR0T3ZDWtDvROy7kmaAnyDrHncl4GobgH+Jv2XjKTDJB1yAPsBXTM8rS38YaYroMb24TgNwDvT8vuAOyIbA/4Pkt6VnitJL0n7bCObarDg52TnmR+KbGjgTWSnS+5I228FPlzYWVIh0dwCfDglByS9tFwdSyh8CWxM9XtnL+9F95gfAY6T1CDpCPYOZTyBLEFvkTSV7IKCPsfRi5+ROr0lvYjsFFJ3DwJTJJ2U9hsl6dh0EcIREXE7WfKdSNYC7F6/vpoIPJUSwtFk02EW7FI2HDRkpxTfWfg9Ujbf8nPITtlNT//5jyI7j1/Kz8lOL5IS0cb0u/YI2XSlKJub+cii5zy78D6Qfj/T8iNkrRZIrY9kn/dC0vMi4q6I+BywgX2Hqq4LTgq10VS4JJWsE/NW4PN9OUBE3Ep2fv1Xku4l6zTb7w+50v26OZOs+b+S7HTOs/pwnHbgZcomlZ8J/HMqPwM4W1Jh1NbCFKgLgE9Iuif9wT1C9h9k4bTUHWStjKfS+keAVmWzTt0PnJvK/4Xs3PnK9L7+Sy917BIRm8k6M+8jSy539/RekJ1y2aPscuKPkp1S+ANZh+0VZB3SRMRvyU63PZDeu1/Qg17iKOcqYJyk1WTv9fISx32GLMFcmt7/FWSn80YA89PneQ9wRYrhv4G3p9/RV1cQQ3c/IWsxrCbrXL6zaNtcss/oxoi4H/gs2eyAK4HbyDrAHyc7l/8rsvdsdZnXuRg4IT33EvYOof1DYFL6PfgQWf9SwYNkE06tBg4ie/8g+/v7iqRlZC2xgu7vxb9Jujf9fv+SrMO5rniUVDPLhXTKdFFEvKjGoQxpbimYmVkXtxTMzKyLWwpmZtbFScHMzLo4KZiZWRcnBTMz6+KkYGZmXf4/coySlscDxUIAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aShHwxvw6hml"
      },
      "source": [
        "## Mean Absolute Error [MAE]\n",
        "\n",
        "Mean absolute error, on the other hand, is measured as the average of sum of absolute differences between predictions and actual observations. \n",
        "\n",
        "Like MSE, this as well measures the magnitude of error without considering their direction. \n",
        "\n",
        "Unlike MSE, MAE needs more complicated tools such as linear programming to compute the gradients. Plus MAE is more robust to outliers since it does not make use of square.\n",
        "\n",
        "Let's assume there are $n$ data samples, for $i^{th}$ sample; the actual output is $y_i$ and $\\hat{y}_i$ is the estimated output from the regression model. \n",
        "\n",
        "We first take the absolute difference between the original and estimated output with $|y_i - \\hat{y}_i|2$. Then we take sum of the absolute differences for all the samples. And finally divide it by the total count of samples, which is $n$. \n",
        "\n",
        "$$MSE = \\frac{\\sum_{i=1}^{n}|y_i - \\hat{y}_i|}{n}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI9_GEL86hmn"
      },
      "source": [
        "model = keras.Sequential([\n",
        "        tf.keras.layers.Dense(100, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(50, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(20, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='mae',\n",
        "              metrics=['mae'])\n",
        "\n",
        "mae_model = model.fit(train_features, train_labels, epochs=250, validation_split = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IEl3-k3bn7N"
      },
      "source": [
        "## Question 2\n",
        "\n",
        "Now that you know how MAE works, you need to plot the behavior of MAE for the synthetic errors given.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYyGYH4zbn7N"
      },
      "source": [
        "### Answer 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK1qdGtBbn7N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "e8541a3b-37f9-4ad5-b297-ea9bb5307675"
      },
      "source": [
        "errors = np.arange(0, 250)\n",
        "n = len(errors)\n",
        "\n",
        "plt.plot(errors, mae_model.history['mae'], c='#0095B6', marker='o')\n",
        "plt.grid()\n",
        "plt.xlabel('Difference between actual and estimated ouputs')\n",
        "plt.ylabel('Mean Absolute Errors')\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIFJ88ER6s7w"
      },
      "source": [
        "## Mean Squared Logarithmic Error [MSLE]\n",
        "\n",
        "MSLE is just like MSE, but we have to take $log$ of the actual and estimated outputs because squaring and averaging. \n",
        "\n",
        "The introduction of the logarithm makes MSLE only care about the relative difference between the true and the predicted value, or in other words, it only cares about the percentual difference between them.\n",
        "\n",
        "This means that MSLE will treat small differences between small true and predicted values approximately the same as big differences between large true and predicted values.\n",
        "\n",
        "We can use MSLE when we don't want large errors to be significantly more penalized than small ones, in those cases where the range of the target value is large.\n",
        "\n",
        "*Example*: You want to predict future house prices, and your dataset includes homes that are orders of magnitude different in price. The price is a continuous value, and therefore, we want to do regression. MSLE can here be used as the loss function.\n",
        "\n",
        "$$MSLE = \\frac{\\sum_{i=1}^{n}(\\log(y_i+1) - \\log(\\hat{y}_i+1))^2}{n}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBkzaP9R7KnB"
      },
      "source": [
        "model = keras.Sequential([\n",
        "        tf.keras.layers.Dense(100, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(50, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(20, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss=tf.keras.losses.MeanSquaredLogarithmicError(),\n",
        "              metrics=['mean_squared_logarithmic_error'])\n",
        "\n",
        "msle_model = model.fit(train_features, train_labels, epochs=150, validation_split = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc_jN5XwcBu9"
      },
      "source": [
        "## Question 3\n",
        "\n",
        "Now that you know how MSLE works, you need to plot the behavior of MSLE for the synthetic errors given.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_USeo3P7cBu-"
      },
      "source": [
        "### Answer 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(msle_model.history.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73xG9JdBtLVM",
        "outputId": "b8c95a86-3a69-402e-fed0-571fce744f26"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'mean_squared_logarithmic_error', 'val_loss', 'val_mean_squared_logarithmic_error'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHr_XxgUcBu-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "b089e225-93cc-4f23-ab7b-d2a1aec00d2c"
      },
      "source": [
        "actual_outputs = np.arange(0, 150)\n",
        "n = len(actual_outputs)\n",
        "estimated_outputs = np.zeros(n)\n",
        "\n",
        "plt.plot(actual_outputs, msle_model.history['mean_squared_logarithmic_error'], c='#F47789', marker='o')\n",
        "plt.grid()\n",
        "plt.xlabel('Actual ouputs')\n",
        "plt.ylabel('Mean Squared Logarithmic Errors')\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BylzTZ1W9Ma"
      },
      "source": [
        "## Question 4\n",
        "\n",
        "Why do we add $1$ to the outputs before passing it through $\\log()$? \n",
        "\n",
        "## Answer 4\n",
        "In case we start with 0 being passed in log() it will equal not defined which will throw an error when trying to visualize the data. That is not to say that expected or actual y cannot be 0 because that is possible given the right parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaQiO_XeYTjE"
      },
      "source": [
        "## Question 5\n",
        "\n",
        "Write your observations about MSE, MAE, and MSLE; and compare the results achieved with all 3 loss functions. \n",
        "\n",
        "## Answer 5\n",
        "Mean Squared Error (MSE) or the first graph seemed to have way more predicted errors than actual errors initially, but it went down dramatically in further epochs just like MAE and MSLE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Efp4KP5GfDL7"
      },
      "source": [
        "## Question 6\n",
        "\n",
        "Plug-in any of the loss functions from [TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/losses) docs to the `model.compile` method and see if the difference in model performance as compared to MSE, MAE, and MSLE.\n",
        "\n",
        "## Answer 6 \n",
        "I used the Squared Hinge loss function and got a 0.00 repeating loss on every epoch except the first where I got 0.4796. I imagine this is a case of overfitting where the data was able to be memorized pretty early on in the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDWlkms1flkZ"
      },
      "source": [
        "model = keras.Sequential([\n",
        "        tf.keras.layers.Dense(100, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(50, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(20, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='sgd', \n",
        "              loss=tf.keras.losses.SquaredHinge())\n",
        "\n",
        "model.fit(train_features, train_labels, epochs=250, validation_split = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mupD9JvzD1BU"
      },
      "source": [
        "#Fun Fact\n",
        "\n",
        "Google Translate is getting better all the time, but it's still not perfect. Translate a sentence into another language and back into English, and you might get a hilarious surprise. That's what Malinda Kathleen Reese got when she reverse Google Translated the lyrics to \"Let It Go\" from Disney's Frozen into Chinese, Macedonian, French, Polish, Creole, Tamil and others. It doesn't come out as utter gibberish, but as a slightly off version with a slightly different message from the original. Which makes it even funnier. Plus, Malinda can really sing.\n",
        "\n",
        "Link to video: https://www.youtube.com/watch?v=2bVAoVlFYf0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t0A5Xui7sum"
      },
      "source": [
        "# Classification Losses\n",
        "\n",
        "In classification, the outputs are in form of a class or a category. The label or number assigned to the classes do not have a numerical meaning. \n",
        "\n",
        "For example, an input with class label 0 cannot be numerically compared with an input with class label 1. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERGOjkbwjCT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf5b5e29-e564-4175-cabb-ef9afb2c7eed"
      },
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = tf.keras.datasets.cifar100.load_data(label_mode=\"coarse\")\n",
        "\n",
        "training_images=training_images.reshape(50000, 32, 32, 3)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 32, 32, 3)\n",
        "test_images=test_images/255.0"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 2s 0us/step\n",
            "169017344/169001437 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EbtSlPYZYju"
      },
      "source": [
        "## Kullback-Leibler Divergence [KDL]\n",
        "\n",
        "Kullback Leibler Divergence Loss is a measure of how a distribution varies from a reference distribution (or a baseline distribution). A Kullback Leibler Divergence Loss of zero means that both the probability distributions are identical.\n",
        "\n",
        "The number of information lost in the predicted distribution is used as a measure.\n",
        "\n",
        "$$KDL(p||q) = \\int_x p(x) \\log \\frac{p(x)}{q(x)} dx$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkyXvdIQZZyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09ff37f6-8205-454f-b819-0144d64bf5ae"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(100, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='kl_divergence', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=50, validation_data=(test_images, test_labels))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 16s 5ms/step - loss: 437.4924 - accuracy: 0.0035 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 437.4921 - accuracy: 0.0057 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4925 - accuracy: 0.0047 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4921 - accuracy: 0.0084 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 437.4920 - accuracy: 0.0120 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4920 - accuracy: 0.0176 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4919 - accuracy: 0.0103 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 437.4921 - accuracy: 0.0085 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4925 - accuracy: 0.0083 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4919 - accuracy: 0.0122 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4926 - accuracy: 0.0081 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4920 - accuracy: 0.0093 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 437.4922 - accuracy: 0.0120 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 437.4919 - accuracy: 0.0099 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 437.4923 - accuracy: 0.0118 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4924 - accuracy: 0.0112 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4920 - accuracy: 0.0096 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 437.4919 - accuracy: 0.0095 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4919 - accuracy: 0.0106 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 437.4918 - accuracy: 0.0140 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 437.4920 - accuracy: 0.0094 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 437.4926 - accuracy: 0.0116 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 437.4920 - accuracy: 0.0124 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4920 - accuracy: 0.0139 - val_loss: 437.4907 - val_accuracy: 0.0500\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 437.4920 - accuracy: 0.0152 - val_loss: 437.4907 - val_accuracy: 0.0500\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 437.4921 - accuracy: 0.0125 - val_loss: 437.4907 - val_accuracy: 0.0500\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 437.4919 - accuracy: 0.0150 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4921 - accuracy: 0.0105 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 437.4924 - accuracy: 0.0108 - val_loss: 437.4907 - val_accuracy: 0.0500\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4922 - accuracy: 0.0125 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 437.4920 - accuracy: 0.0085 - val_loss: 437.4907 - val_accuracy: 0.0500\n",
            "Epoch 32/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4919 - accuracy: 0.0114 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4919 - accuracy: 0.0085 - val_loss: 437.4907 - val_accuracy: 0.0500\n",
            "Epoch 34/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 437.4920 - accuracy: 0.0093 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 437.4924 - accuracy: 0.0113 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 437.4924 - accuracy: 0.0107 - val_loss: 437.4907 - val_accuracy: 0.0500\n",
            "Epoch 37/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4924 - accuracy: 0.0100 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4920 - accuracy: 0.0111 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 437.4919 - accuracy: 0.0087 - val_loss: 437.4907 - val_accuracy: 0.0500\n",
            "Epoch 40/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 437.4928 - accuracy: 0.0112 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4922 - accuracy: 0.0096 - val_loss: 437.4907 - val_accuracy: 0.0500\n",
            "Epoch 42/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4924 - accuracy: 0.0098 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 437.4917 - accuracy: 0.0097 - val_loss: 437.4907 - val_accuracy: 0.0500\n",
            "Epoch 44/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4920 - accuracy: 0.0095 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4919 - accuracy: 0.0101 - val_loss: 437.4907 - val_accuracy: 0.0500\n",
            "Epoch 46/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4922 - accuracy: 0.0075 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4923 - accuracy: 0.0100 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 437.4918 - accuracy: 0.0091 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 437.4921 - accuracy: 0.0103 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 437.4919 - accuracy: 0.0105 - val_loss: 437.4907 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff7760f38d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIOrqUGTYjD8"
      },
      "source": [
        "##Binary Cross Entropy\n",
        "Cross-entropy is a measure from the field of information theory, building upon entropy and generally calculating the difference between two probability distributions. It is closely related to but is different from KL divergence that calculates the relative entropy between two probability distributions, whereas cross-entropy can be thought to calculate the total entropy between the distributions.\n",
        "\n",
        "Cross-entropy is also related to and often confused with logistic loss, called log loss. Although the two measures are derived from a different source, when used as loss functions for classification models, both measures calculate the same quantity and can be used interchangeably.\n",
        "\n",
        "Binary crossentropy is a loss function that is used in binary classification tasks. These are tasks that answer a question with only two choices (yes or no, A or B, 0 or 1, left or right). Several independent such questions can be answered at the same time, as in multi-label classification or in binary image segmentation. Formally, this loss is equal to the average of the categorical crossentropy loss on many two-category tasks.\n",
        "\n",
        "$$BCE = -\\frac{1}{N} \\sum_{i=1}^N y_i \\cdot \\log(p(y_i)) + (1-y_i) \\cdot \\log(1- p(y_i))$$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_labels = tf.reshape(tf.one_hot(training_labels, 100), [training_labels.shape[0], 100])\n",
        "print(training_labels.shape)\n",
        "\n",
        "test_labels = tf.reshape(tf.one_hot(test_labels, 100), [test_labels.shape[0], 100])\n",
        "print(test_labels.shape)"
      ],
      "metadata": {
        "id": "Ckc0jYu_LwkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aaab1d9-c325-40c0-d59d-c9a2b1f0320d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 100)\n",
            "(10000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRvhNnnJYjOF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0645eac-19d2-4b0b-c348-5ba7f1d53d50"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(100, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=50, validation_data=(test_images, test_labels))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0419 - accuracy: 0.1489 - val_loss: 0.0341 - val_accuracy: 0.2383\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0330 - accuracy: 0.2673 - val_loss: 0.0319 - val_accuracy: 0.2921\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0312 - accuracy: 0.3178 - val_loss: 0.0305 - val_accuracy: 0.3367\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0299 - accuracy: 0.3498 - val_loss: 0.0305 - val_accuracy: 0.3411\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0289 - accuracy: 0.3758 - val_loss: 0.0292 - val_accuracy: 0.3608\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0279 - accuracy: 0.3990 - val_loss: 0.0282 - val_accuracy: 0.3915\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0272 - accuracy: 0.4170 - val_loss: 0.0276 - val_accuracy: 0.4050\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0267 - accuracy: 0.4312 - val_loss: 0.0283 - val_accuracy: 0.3915\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0262 - accuracy: 0.4444 - val_loss: 0.0267 - val_accuracy: 0.4308\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0257 - accuracy: 0.4559 - val_loss: 0.0264 - val_accuracy: 0.4369\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0253 - accuracy: 0.4666 - val_loss: 0.0262 - val_accuracy: 0.4456\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0249 - accuracy: 0.4719 - val_loss: 0.0260 - val_accuracy: 0.4494\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0246 - accuracy: 0.4826 - val_loss: 0.0261 - val_accuracy: 0.4520\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0243 - accuracy: 0.4887 - val_loss: 0.0256 - val_accuracy: 0.4595\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0241 - accuracy: 0.4965 - val_loss: 0.0261 - val_accuracy: 0.4529\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0238 - accuracy: 0.5016 - val_loss: 0.0255 - val_accuracy: 0.4626\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0235 - accuracy: 0.5065 - val_loss: 0.0255 - val_accuracy: 0.4636\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0234 - accuracy: 0.5115 - val_loss: 0.0256 - val_accuracy: 0.4603\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0232 - accuracy: 0.5155 - val_loss: 0.0251 - val_accuracy: 0.4731\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0230 - accuracy: 0.5207 - val_loss: 0.0250 - val_accuracy: 0.4752\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0228 - accuracy: 0.5236 - val_loss: 0.0251 - val_accuracy: 0.4717\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0227 - accuracy: 0.5277 - val_loss: 0.0254 - val_accuracy: 0.4662\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0225 - accuracy: 0.5313 - val_loss: 0.0253 - val_accuracy: 0.4747\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0223 - accuracy: 0.5371 - val_loss: 0.0255 - val_accuracy: 0.4709\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0222 - accuracy: 0.5411 - val_loss: 0.0252 - val_accuracy: 0.4682\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0221 - accuracy: 0.5424 - val_loss: 0.0246 - val_accuracy: 0.4876\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0219 - accuracy: 0.5462 - val_loss: 0.0254 - val_accuracy: 0.4677\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0218 - accuracy: 0.5504 - val_loss: 0.0252 - val_accuracy: 0.4805\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0217 - accuracy: 0.5518 - val_loss: 0.0250 - val_accuracy: 0.4784\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0216 - accuracy: 0.5541 - val_loss: 0.0250 - val_accuracy: 0.4791\n",
            "Epoch 31/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0215 - accuracy: 0.5582 - val_loss: 0.0253 - val_accuracy: 0.4731\n",
            "Epoch 32/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0213 - accuracy: 0.5589 - val_loss: 0.0251 - val_accuracy: 0.4748\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0212 - accuracy: 0.5636 - val_loss: 0.0252 - val_accuracy: 0.4813\n",
            "Epoch 34/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0212 - accuracy: 0.5655 - val_loss: 0.0253 - val_accuracy: 0.4761\n",
            "Epoch 35/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0211 - accuracy: 0.5672 - val_loss: 0.0252 - val_accuracy: 0.4782\n",
            "Epoch 36/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0210 - accuracy: 0.5691 - val_loss: 0.0252 - val_accuracy: 0.4811\n",
            "Epoch 37/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0209 - accuracy: 0.5723 - val_loss: 0.0251 - val_accuracy: 0.4843\n",
            "Epoch 38/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0208 - accuracy: 0.5769 - val_loss: 0.0253 - val_accuracy: 0.4818\n",
            "Epoch 39/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0207 - accuracy: 0.5755 - val_loss: 0.0252 - val_accuracy: 0.4875\n",
            "Epoch 40/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0207 - accuracy: 0.5765 - val_loss: 0.0257 - val_accuracy: 0.4760\n",
            "Epoch 41/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0206 - accuracy: 0.5793 - val_loss: 0.0256 - val_accuracy: 0.4785\n",
            "Epoch 42/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0205 - accuracy: 0.5796 - val_loss: 0.0256 - val_accuracy: 0.4843\n",
            "Epoch 43/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0204 - accuracy: 0.5842 - val_loss: 0.0258 - val_accuracy: 0.4813\n",
            "Epoch 44/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0203 - accuracy: 0.5858 - val_loss: 0.0258 - val_accuracy: 0.4784\n",
            "Epoch 45/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0203 - accuracy: 0.5867 - val_loss: 0.0257 - val_accuracy: 0.4783\n",
            "Epoch 46/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0202 - accuracy: 0.5871 - val_loss: 0.0253 - val_accuracy: 0.4886\n",
            "Epoch 47/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0202 - accuracy: 0.5890 - val_loss: 0.0256 - val_accuracy: 0.4776\n",
            "Epoch 48/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0201 - accuracy: 0.5904 - val_loss: 0.0256 - val_accuracy: 0.4774\n",
            "Epoch 49/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0200 - accuracy: 0.5931 - val_loss: 0.0259 - val_accuracy: 0.4752\n",
            "Epoch 50/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0199 - accuracy: 0.5936 - val_loss: 0.0260 - val_accuracy: 0.4812\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff75e042b10>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 7\n",
        "\n",
        "Do you see any problems/errors with the above code? Please describe.\n",
        "\n",
        "## Answer 7\n",
        "The only discernable problem I can see it the low accuracy. It climbs to 0.59 by the last epoch, but this is typically not enough for an accurate prediction."
      ],
      "metadata": {
        "id": "eAAuecZfTfx2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDBdn-P976v9"
      },
      "source": [
        "## Categorical Cross Entropy\n",
        "\n",
        "This is the most common setting for classification problems. Cross-entropy loss increases as the **predicted probability** strays away from the **actual label**.\n",
        "\n",
        "Note that we have to compare the probabilities (e.g. [0.20, 0.75, 0.05]) of all the classes with the actual labels (e.g., [0, 1, 0]). The actual labels would be one-hot encoding.\n",
        "\n",
        "An important aspect of this is that cross entropy loss penalizes heavily the predictions that are confident but wrong.\n",
        "\n",
        "We are multiplying the log of the actual predicted probability for the ground truth class.\n",
        "\n",
        "$$CCE = -\\frac{1}{N}\\sum_{i=1}^{N}y_i\\log(\\hat{y}_i)$$ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uskCvsUSrR0o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ccce41c-f263-4f05-fa29-d4cbc975b1ec"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(100, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=25, validation_data=(test_images, test_labels))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.5721 - accuracy: 0.2055 - val_loss: 2.3648 - val_accuracy: 0.2654\n",
            "Epoch 2/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 2.2317 - accuracy: 0.3073 - val_loss: 2.2334 - val_accuracy: 0.3084\n",
            "Epoch 3/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 2.0952 - accuracy: 0.3477 - val_loss: 2.0798 - val_accuracy: 0.3475\n",
            "Epoch 4/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 2.0030 - accuracy: 0.3769 - val_loss: 2.0015 - val_accuracy: 0.3719\n",
            "Epoch 5/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.9210 - accuracy: 0.4040 - val_loss: 2.0183 - val_accuracy: 0.3700\n",
            "Epoch 6/25\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8616 - accuracy: 0.4166 - val_loss: 2.0098 - val_accuracy: 0.3791\n",
            "Epoch 7/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.8090 - accuracy: 0.4333 - val_loss: 1.8767 - val_accuracy: 0.4146\n",
            "Epoch 8/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.7624 - accuracy: 0.4473 - val_loss: 1.8469 - val_accuracy: 0.4237\n",
            "Epoch 9/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.7276 - accuracy: 0.4568 - val_loss: 1.8136 - val_accuracy: 0.4368\n",
            "Epoch 10/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.6914 - accuracy: 0.4699 - val_loss: 1.8154 - val_accuracy: 0.4397\n",
            "Epoch 11/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6597 - accuracy: 0.4767 - val_loss: 1.7963 - val_accuracy: 0.4421\n",
            "Epoch 12/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.6336 - accuracy: 0.4869 - val_loss: 1.8121 - val_accuracy: 0.4373\n",
            "Epoch 13/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.6009 - accuracy: 0.4962 - val_loss: 1.8041 - val_accuracy: 0.4443\n",
            "Epoch 14/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5820 - accuracy: 0.5021 - val_loss: 1.7827 - val_accuracy: 0.4473\n",
            "Epoch 15/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5604 - accuracy: 0.5088 - val_loss: 1.7451 - val_accuracy: 0.4589\n",
            "Epoch 16/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5407 - accuracy: 0.5138 - val_loss: 1.7885 - val_accuracy: 0.4448\n",
            "Epoch 17/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5218 - accuracy: 0.5187 - val_loss: 1.7962 - val_accuracy: 0.4483\n",
            "Epoch 18/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5014 - accuracy: 0.5247 - val_loss: 1.7658 - val_accuracy: 0.4540\n",
            "Epoch 19/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.4840 - accuracy: 0.5290 - val_loss: 1.8286 - val_accuracy: 0.4433\n",
            "Epoch 20/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.4656 - accuracy: 0.5351 - val_loss: 1.8028 - val_accuracy: 0.4521\n",
            "Epoch 21/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.4483 - accuracy: 0.5400 - val_loss: 1.7788 - val_accuracy: 0.4550\n",
            "Epoch 22/25\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4384 - accuracy: 0.5412 - val_loss: 1.7791 - val_accuracy: 0.4597\n",
            "Epoch 23/25\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.4205 - accuracy: 0.5486 - val_loss: 1.8029 - val_accuracy: 0.4506\n",
            "Epoch 24/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.4105 - accuracy: 0.5495 - val_loss: 1.7648 - val_accuracy: 0.4593\n",
            "Epoch 25/25\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.4067 - accuracy: 0.5516 - val_loss: 1.7798 - val_accuracy: 0.4533\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff7511f9250>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 8\n",
        "\n",
        "Now that you know how CCE works, you need to code it. It should give the same answer as `tf.keras.metrics.categorical_crossentropy` would."
      ],
      "metadata": {
        "id": "KYuLKOGSR4yS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer 8"
      ],
      "metadata": {
        "id": "TAtqr73-SLUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.scale import LogisticTransform\n",
        "def categorical_crossentropy(true, pred):\n",
        "  loss = -np.sum(true * np.log(pred + 10**-100))\n",
        "  return loss\n",
        "\n",
        "true = tf.constant([[0.0, 1.0, 0.0],\n",
        "                    [1.0, 0.0, 0.0],\n",
        "                    [1.0, 0.0, 0.0],\n",
        "                    [0.0, 0.0, 1.0]])\n",
        "pred = tf.constant([[0.20, 0.70, 0.10],\n",
        "                    [0.80, 0.05, 0.15],\n",
        "                    [0.75, 0.10, 0.15],\n",
        "                    [0.25, 0.15, 0.60]])\n",
        "\n",
        "loss = categorical_crossentropy(true, pred)\n",
        "print(loss)\n",
        "\n",
        "loss = tf.keras.metrics.categorical_crossentropy(true, pred)\n",
        "loss = tf.reduce_mean(loss)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "mxzrT-GKSRSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56b9c54c-546a-4373-abbb-b49a1e61bcb1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3783262\n",
            "tf.Tensor(0.34458154, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CHuqni18OPL"
      },
      "source": [
        "## Sparse Categorical Cross Entropy\n",
        "\n",
        "Both, Categorical Cross Entropy [CCE] and Sparse Categorical Cross Entropy [SCCE] have the same loss function. The only difference is the format of $y_i$ (i.e., true labels).\n",
        "\n",
        "If $y_i$'s are one-hot encoded, we should use CCE. Examples (for a 3-class classification): [1,0,0], [0,1,0], [0,0,1]\n",
        "\n",
        "But if $y_i$'s are integers, use SCCE. Examples for above 3-class classification problem: [1], [2], [3]\n",
        "\n",
        "The usage entirely depends on how we load our dataset. One advantage of using sparse categorical cross entropy is it saves time in memory as well as computation because it simply uses a single integer for a class, rather than a whole vector.\n",
        "\n",
        "$$SCCE = -\\log(\\hat{y}_i)$$ for $i$ where $one\\text{-}hot\\text{-}encoding[i] = 1$ "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = tf.keras.datasets.cifar100.load_data(label_mode=\"coarse\")\n",
        "\n",
        "training_images=training_images.reshape(50000, 32, 32, 3)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 32, 32, 3)\n",
        "test_images=test_images/255.0"
      ],
      "metadata": {
        "id": "tb6GisE4SkhX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcFK26KvCp-g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5e340af-28f8-4b2a-8e81-202b01b3534e"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(100, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=50, validation_data=(test_images, test_labels))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.5801 - accuracy: 0.2052 - val_loss: 2.3065 - val_accuracy: 0.2885\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 2.2168 - accuracy: 0.3142 - val_loss: 2.1397 - val_accuracy: 0.3320\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 2.0603 - accuracy: 0.3601 - val_loss: 2.0261 - val_accuracy: 0.3717\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.9529 - accuracy: 0.3918 - val_loss: 2.0243 - val_accuracy: 0.3703\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.8726 - accuracy: 0.4182 - val_loss: 1.9512 - val_accuracy: 0.3994\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.8090 - accuracy: 0.4350 - val_loss: 1.9100 - val_accuracy: 0.4064\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.7516 - accuracy: 0.4528 - val_loss: 1.8488 - val_accuracy: 0.4278\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.7112 - accuracy: 0.4648 - val_loss: 1.8205 - val_accuracy: 0.4361\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.6757 - accuracy: 0.4750 - val_loss: 1.8165 - val_accuracy: 0.4350\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6388 - accuracy: 0.4868 - val_loss: 1.7577 - val_accuracy: 0.4523\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.6113 - accuracy: 0.4936 - val_loss: 1.7561 - val_accuracy: 0.4534\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5863 - accuracy: 0.5023 - val_loss: 1.7357 - val_accuracy: 0.4648\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5624 - accuracy: 0.5072 - val_loss: 1.7316 - val_accuracy: 0.4648\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5373 - accuracy: 0.5150 - val_loss: 1.7423 - val_accuracy: 0.4633\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5202 - accuracy: 0.5199 - val_loss: 1.7251 - val_accuracy: 0.4711\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.4988 - accuracy: 0.5260 - val_loss: 1.7305 - val_accuracy: 0.4717\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.4869 - accuracy: 0.5294 - val_loss: 1.7694 - val_accuracy: 0.4638\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.4681 - accuracy: 0.5342 - val_loss: 1.7261 - val_accuracy: 0.4713\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.4479 - accuracy: 0.5399 - val_loss: 1.7139 - val_accuracy: 0.4760\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.4351 - accuracy: 0.5446 - val_loss: 1.7415 - val_accuracy: 0.4642\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.4221 - accuracy: 0.5469 - val_loss: 1.7203 - val_accuracy: 0.4798\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.4072 - accuracy: 0.5536 - val_loss: 1.7825 - val_accuracy: 0.4603\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.3914 - accuracy: 0.5549 - val_loss: 1.7467 - val_accuracy: 0.4739\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.3834 - accuracy: 0.5583 - val_loss: 1.7530 - val_accuracy: 0.4721\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.3689 - accuracy: 0.5622 - val_loss: 1.7295 - val_accuracy: 0.4800\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3613 - accuracy: 0.5664 - val_loss: 1.7513 - val_accuracy: 0.4786\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.3501 - accuracy: 0.5671 - val_loss: 1.7191 - val_accuracy: 0.4819\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.3393 - accuracy: 0.5731 - val_loss: 1.7864 - val_accuracy: 0.4668\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3260 - accuracy: 0.5757 - val_loss: 1.7734 - val_accuracy: 0.4691\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.3210 - accuracy: 0.5771 - val_loss: 1.7745 - val_accuracy: 0.4736\n",
            "Epoch 31/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.3038 - accuracy: 0.5817 - val_loss: 1.7347 - val_accuracy: 0.4780\n",
            "Epoch 32/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2958 - accuracy: 0.5855 - val_loss: 1.7618 - val_accuracy: 0.4787\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2856 - accuracy: 0.5868 - val_loss: 1.7776 - val_accuracy: 0.4702\n",
            "Epoch 34/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2795 - accuracy: 0.5894 - val_loss: 1.7810 - val_accuracy: 0.4697\n",
            "Epoch 35/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2688 - accuracy: 0.5936 - val_loss: 1.7824 - val_accuracy: 0.4729\n",
            "Epoch 36/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2679 - accuracy: 0.5917 - val_loss: 1.7953 - val_accuracy: 0.4683\n",
            "Epoch 37/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2544 - accuracy: 0.5963 - val_loss: 1.7763 - val_accuracy: 0.4749\n",
            "Epoch 38/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2449 - accuracy: 0.5993 - val_loss: 1.8034 - val_accuracy: 0.4763\n",
            "Epoch 39/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2345 - accuracy: 0.6017 - val_loss: 1.8330 - val_accuracy: 0.4694\n",
            "Epoch 40/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2339 - accuracy: 0.6020 - val_loss: 1.8219 - val_accuracy: 0.4733\n",
            "Epoch 41/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2258 - accuracy: 0.6040 - val_loss: 1.8221 - val_accuracy: 0.4741\n",
            "Epoch 42/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2166 - accuracy: 0.6078 - val_loss: 1.8338 - val_accuracy: 0.4763\n",
            "Epoch 43/50\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2102 - accuracy: 0.6087 - val_loss: 1.8280 - val_accuracy: 0.4728\n",
            "Epoch 44/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2022 - accuracy: 0.6134 - val_loss: 1.8832 - val_accuracy: 0.4705\n",
            "Epoch 45/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1980 - accuracy: 0.6149 - val_loss: 1.8609 - val_accuracy: 0.4643\n",
            "Epoch 46/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1884 - accuracy: 0.6173 - val_loss: 1.8769 - val_accuracy: 0.4692\n",
            "Epoch 47/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1824 - accuracy: 0.6158 - val_loss: 1.8723 - val_accuracy: 0.4658\n",
            "Epoch 48/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.1754 - accuracy: 0.6199 - val_loss: 1.8964 - val_accuracy: 0.4697\n",
            "Epoch 49/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1673 - accuracy: 0.6215 - val_loss: 1.8753 - val_accuracy: 0.4705\n",
            "Epoch 50/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.1669 - accuracy: 0.6223 - val_loss: 1.8825 - val_accuracy: 0.4688\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff75108c950>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhV-fVzcNc3p"
      },
      "source": [
        "## Question 9\n",
        "\n",
        "What is the difference between a Multi-class and Multi-label Classification problem, and what sort of loss function would we need to learn them?\n",
        "\n",
        "## Answer 9\n",
        "Multi-class classification tends to be mutually exclusive between the classes and their given labels. Multi-label classification can have multiple labels corresponding to each. A good way of learning these classifications would be looking at Sparse Cross entropy and Categorical Cross entropy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITEN1-3-OQwd"
      },
      "source": [
        "## Question 10\n",
        "What is the relationship between Binary Cross entropy and Categorical Cross entropy?\n",
        "\n",
        "## Answer 10\n",
        "In the same way binary cross entropy returns 0 or 1, true or false or a classification, it is just like a categorical cross entropy where it puts features into categories by classifying them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGwk3Z0xOmRk"
      },
      "source": [
        "## Question 11\n",
        "\n",
        "What is the relationship between Sparse Cross entropy and Categorical Cross entropy?\n",
        "\n",
        "## Answer 11\n",
        "While they use the same loss function, the only major difference is the format of classes and labels. With sparse, it uses single label, multi class classification meaning that each class can only belong to one data value/label. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RDBtUuYjuFh"
      },
      "source": [
        "# **Upload this Day 9 Colab Notebook to your Github repository under \"Day 9\" folder. Also add your *Reflection* on today's learning in README.md**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgg0bvRjS9un"
      },
      "source": [
        "Sources:\n",
        "\n",
        "https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23\n",
        "\n",
        "https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-logarithmic-error-(msle)"
      ]
    }
  ]
}